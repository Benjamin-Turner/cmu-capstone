{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T05:34:00.705096Z",
     "start_time": "2019-07-12T05:34:00.700112Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T05:34:01.007466Z",
     "start_time": "2019-07-12T05:34:00.921518Z"
    }
   },
   "outputs": [],
   "source": [
    "# import final dataframe\n",
    "cwd = os.getcwd()\n",
    "final_df = pickle.load(open( cwd+\"\\\\data\\\\final_df.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T00:54:20.284941Z",
     "start_time": "2019-07-12T00:54:20.269288Z"
    }
   },
   "source": [
    "# 1. Handling Categorical Features via One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T05:34:01.652568Z",
     "start_time": "2019-07-12T05:34:01.612709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry</th>\n",
       "      <th>sub_industry</th>\n",
       "      <th>shipper</th>\n",
       "      <th>std_service_type</th>\n",
       "      <th>std_weight</th>\n",
       "      <th>freight_charges</th>\n",
       "      <th>zone</th>\n",
       "      <th>sender_state</th>\n",
       "      <th>recipient_state</th>\n",
       "      <th>same_MSA</th>\n",
       "      <th>sender_in_MSA</th>\n",
       "      <th>rec_in_MSA</th>\n",
       "      <th>sender_MSA_num</th>\n",
       "      <th>rec_MSA_num</th>\n",
       "      <th>week_number</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>ups</td>\n",
       "      <td>Ground</td>\n",
       "      <td>48.0</td>\n",
       "      <td>34.39</td>\n",
       "      <td>2</td>\n",
       "      <td>IN</td>\n",
       "      <td>MI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99014</td>\n",
       "      <td>24340</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RETAIL</td>\n",
       "      <td>ECOMMERCE</td>\n",
       "      <td>fedex</td>\n",
       "      <td>Ground</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.22</td>\n",
       "      <td>6</td>\n",
       "      <td>MT</td>\n",
       "      <td>OH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99026</td>\n",
       "      <td>17460</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>fedex</td>\n",
       "      <td>Home Delivery</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.19</td>\n",
       "      <td>5</td>\n",
       "      <td>IN</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34620</td>\n",
       "      <td>36740</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RETAIL</td>\n",
       "      <td>FOOD STORES</td>\n",
       "      <td>ups</td>\n",
       "      <td>Ground</td>\n",
       "      <td>50.0</td>\n",
       "      <td>109.72</td>\n",
       "      <td>4</td>\n",
       "      <td>WI</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31540</td>\n",
       "      <td>16020</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SERVICES</td>\n",
       "      <td>TRAVEL SERVICES &amp; TRAVEL DOCUMENTS</td>\n",
       "      <td>fedex</td>\n",
       "      <td>Ground</td>\n",
       "      <td>44.0</td>\n",
       "      <td>31.57</td>\n",
       "      <td>5</td>\n",
       "      <td>MN</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33460</td>\n",
       "      <td>10580</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   industry                        sub_industry shipper std_service_type  \\\n",
       "0     OTHER                               OTHER     ups           Ground   \n",
       "1    RETAIL                           ECOMMERCE   fedex           Ground   \n",
       "2     OTHER                               OTHER   fedex    Home Delivery   \n",
       "3    RETAIL                         FOOD STORES     ups           Ground   \n",
       "4  SERVICES  TRAVEL SERVICES & TRAVEL DOCUMENTS   fedex           Ground   \n",
       "\n",
       "   std_weight  freight_charges zone sender_state recipient_state same_MSA  \\\n",
       "0        48.0            34.39    2           IN              MI        0   \n",
       "1         3.0            22.22    6           MT              OH        0   \n",
       "2        11.0            13.19    5           IN              FL        0   \n",
       "3        50.0           109.72    4           WI                        0   \n",
       "4        44.0            31.57    5           MN              NY        0   \n",
       "\n",
       "  sender_in_MSA rec_in_MSA sender_MSA_num rec_MSA_num week_number day_of_week  \\\n",
       "0             0          1          99014       24340          25           0   \n",
       "1             0          1          99026       17460          23           2   \n",
       "2             1          1          34620       36740          22           1   \n",
       "3             1          1          31540       16020          23           0   \n",
       "4             1          1          33460       10580          20           2   \n",
       "\n",
       "    Y  \n",
       "0   3  \n",
       "1  18  \n",
       "2   9  \n",
       "3   7  \n",
       "4  12  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T05:34:02.310802Z",
     "start_time": "2019-07-12T05:34:02.106353Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df = final_df.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T05:34:03.969401Z",
     "start_time": "2019-07-12T05:34:03.322140Z"
    }
   },
   "outputs": [],
   "source": [
    "y = final_df.Y\n",
    "final_df = final_df.drop(columns=['Y','sub_industry','sender_MSA_num','rec_MSA_num','industry','week_number'])\n",
    "ohe_df = pd.get_dummies(final_df)\n",
    "X = ohe_df\n",
    "\n",
    "# Free up memory\n",
    "del final_df\n",
    "del ohe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T05:34:06.431822Z",
     "start_time": "2019-07-12T05:34:06.428825Z"
    }
   },
   "outputs": [],
   "source": [
    "# To test\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# # Min max feature scaling\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# X = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T05:34:06.908515Z",
     "start_time": "2019-07-12T05:34:06.900532Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def prepare_data(X, y):\n",
    "    '''\n",
    "    This function will prepare the data for classification.\n",
    "    It expects the following parameters:\n",
    "      - X: feature columns\n",
    "      - y: target variable column\n",
    "      - train_size: proportion of dataset used for training\n",
    "      - random_state: the random seed to use when selecting a subset of rows\n",
    "    \n",
    "    This function returns a dictionary with the following entries\n",
    "      - X_train: the matrix of training data\n",
    "      - y_train: the array of training labels\n",
    "      - X_test: the matrix of testing data\n",
    "      - y_test: the array of testing labels\n",
    "    '''\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=71)    \n",
    "    \n",
    "    # Scale the variables\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # return training and testing data\n",
    "    out = {'X_train':X_train, 'y_train':y_train, \n",
    "           'X_test':X_test, 'y_test':y_test}\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T05:34:08.289820Z",
     "start_time": "2019-07-12T05:34:08.269911Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_classification(model, data_dict,\n",
    "                          cv_parameters = {},\n",
    "                          model_name = None,\n",
    "                          random_state = 0,\n",
    "                          output_to_file = True,\n",
    "                          print_to_screen = True):\n",
    "    '''\n",
    "    This function will fit a classification model to data and print various evaluation\n",
    "    measures. It expects the following parameters\n",
    "      - model: an sklearn model object\n",
    "      - data_dict: the dictionary containing both training and testing data;\n",
    "                   returned by the prepare_data function\n",
    "      - cv_parameters: a dictionary of parameters that should be optimized\n",
    "                       over using cross-validation. Specifically, each named\n",
    "                       entry in the dictionary should correspond to a parameter,\n",
    "                       and each element should be a list containing the values\n",
    "                       to optimize over\n",
    "      - model_name: the name of the model being fit, for printouts\n",
    "      - random_state: the random seed to use\n",
    "      - output_to_file: if the results will be saved to the output file\n",
    "      - print_to_screen: if the results will be printed on screen\n",
    "    \n",
    "    If the model provided does not have a predict_proba function, we will\n",
    "    simply print accuracy diagnostics and return.\n",
    "    \n",
    "    If the model provided does have a predict_proba function, we first\n",
    "    figure out the optimal threshold that maximizes the accuracy and\n",
    "    print out accuracy diagnostics. We then print an ROC curve, sensitivity/\n",
    "    specificity curve, and calibration curve.\n",
    "    \n",
    "    This function returns a dictionary with the following entries\n",
    "      - model: the best fitted model\n",
    "      - y_pred: predictions for the test set\n",
    "      - y_pred_probs: probability predictions for the test set, if the model\n",
    "                      supports them\n",
    "      - y_pred_score: prediction scores for the test set, if the model does not \n",
    "                      output probabilities.\n",
    "    '''\n",
    "        \n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # --------------------------\n",
    "    #   Step 1 - Load the data\n",
    "    # --------------------------\n",
    "    X_train = data_dict['X_train']\n",
    "    y_train = data_dict['y_train']\n",
    "    \n",
    "    X_test = data_dict['X_test']\n",
    "    y_test = data_dict['y_test']\n",
    "      \n",
    "    # --------------------------\n",
    "    #   Step 2 - Fit the model\n",
    "    # --------------------------\n",
    "\n",
    "    cv_model = GridSearchCV(model, cv_parameters, verbose=10, n_jobs=6, cv=3)\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    cv_model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    best_model = cv_model.best_estimator_\n",
    "    \n",
    "    if print_to_screen:\n",
    "\n",
    "        if model_name != None:\n",
    "            print(\"=========================================================\")\n",
    "            print(\"  Model: \" + model_name)\n",
    "            print(\"=========================================================\")\n",
    "\n",
    "        print(\"Fit time: \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "        print(\"Optimal parameters:\")\n",
    "        print(cv_model.best_params_)\n",
    "        print(\"\")\n",
    "    \n",
    "    # -------------------------------\n",
    "    #   Step 3 - Evaluate the model\n",
    "    # -------------------------------\n",
    "    \n",
    "    y_pred_probs = best_model.predict_proba(X_test)[0]\n",
    "    # gets a dictionary of {'class_name': probability}\n",
    "    prob_per_class_dictionary = dict(zip(best_model.classes_, y_pred_probs))\n",
    " \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    if print_to_screen:\n",
    "        print(classification_report(y_test, y_pred, digits = 4))\n",
    "        precision,recall,fscore,support=score(y_test,y_pred,average='weighted')\n",
    "        print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "        print(\"Precision: \", precision)\n",
    "        print(\"Recall: \", recall)\n",
    "        print(\"F1: \", fscore)\n",
    "\n",
    "    # Return the model predictions, and the\n",
    "    # test set\n",
    "    # -------------------------------------\n",
    "    out = {'model':best_model, 'y_pred_labels':y_pred}\n",
    "    out.update({'y_pred_probs':y_pred_probs})\n",
    "\n",
    "# SVC\n",
    "#         y_pred_score = best_model.decision_function(X_test)\n",
    "#         out.update({'y_pred_score':y_pred_score})\n",
    "        \n",
    "    # Output results to file\n",
    "    # ----------------------\n",
    "#     if probs_predicted and output_to_file:\n",
    "#         # Check whether any of the CV parameters are on the edge of\n",
    "#         # the search space\n",
    "#         opt_params_on_edge = find_opt_params_on_edge(cv_model)\n",
    "#         dump_to_output(model_name + \"::search_on_edge\", opt_params_on_edge)\n",
    "#         if print_to_screen:\n",
    "#             print(\"Were parameters on edge? : \" + str(opt_params_on_edge))\n",
    "        \n",
    "#         # Find out how different the scores are for the different values\n",
    "#         # tested for by cross-validation. If they're not too different, then\n",
    "#         # even if the parameters are off the edge of the search grid, we should\n",
    "#         # be ok\n",
    "#         score_variation = find_score_variation(cv_model)\n",
    "#         dump_to_output(model_name + \"::score_variation\", score_variation)\n",
    "#         if print_to_screen:\n",
    "#             print(\"Score variations around CV search grid : \" + str(score_variation))\n",
    "        \n",
    "#         # Print out all the scores\n",
    "#         dump_to_output(model_name + \"::all_cv_scores\", str(cv_model.cv_results_['mean_test_score']))\n",
    "#         if print_to_screen:\n",
    "#             print( str(cv_model.cv_results_['mean_test_score']) )\n",
    "        \n",
    "#         # Dump the AUC to file\n",
    "#         dump_to_output(model_name + \"::roc_auc\", roc_auc_score(y_test, y_pred_probs) )\n",
    "        \n",
    "    return prob_per_class_dictionary, out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T05:34:08.768575Z",
     "start_time": "2019-07-12T05:34:08.761557Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load sklearn utilities\n",
    "# ----------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, brier_score_loss, mean_squared_error, r2_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Load classifiers\n",
    "# ----------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T05:34:12.527520Z",
     "start_time": "2019-07-12T05:34:09.680101Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royce\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "data_dict = prepare_data(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T07:25:32.427373Z",
     "start_time": "2019-07-12T05:34:14.032466Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   9 | elapsed: 12.6min remaining: 44.1min\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   9 | elapsed: 12.7min remaining: 25.4min\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   9 | elapsed: 42.6min remaining: 53.2min\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   9 | elapsed: 43.3min remaining: 34.7min\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   9 | elapsed: 45.2min remaining: 22.6min\n",
      "[Parallel(n_jobs=6)]: Done   7 out of   9 | elapsed: 73.0min remaining: 20.9min\n",
      "[Parallel(n_jobs=6)]: Done   9 out of   9 | elapsed: 73.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   9 out of   9 | elapsed: 73.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "  Model: L2 Logistic Regression\n",
      "=========================================================\n",
      "Fit time: 6677.77 seconds\n",
      "Optimal parameters:\n",
      "{'C': 1}\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4967    0.2239    0.3087      1706\n",
      "           1     0.0000    0.0000    0.0000        97\n",
      "           2     0.3910    0.1286    0.1936      7930\n",
      "           3     0.2325    0.0093    0.0178     10047\n",
      "           4     0.3366    0.8291    0.4788     16713\n",
      "           5     0.0000    0.0000    0.0000      5587\n",
      "           6     0.0000    0.0000    0.0000       159\n",
      "           7     0.2745    0.0394    0.0689      9323\n",
      "           8     0.1983    0.0018    0.0037     12443\n",
      "           9     0.3042    0.7328    0.4300     21474\n",
      "          10     0.0000    0.0000    0.0000      7435\n",
      "          11     0.0000    0.0000    0.0000       128\n",
      "          12     0.2789    0.0344    0.0613      5610\n",
      "          13     0.2000    0.0003    0.0005      7734\n",
      "          14     0.2717    0.5214    0.3572     14062\n",
      "          15     0.0000    0.0000    0.0000      5029\n",
      "          16     0.0000    0.0000    0.0000        93\n",
      "          17     0.2481    0.0874    0.1293      4197\n",
      "          18     0.2222    0.0010    0.0020      5987\n",
      "          19     0.2560    0.7141    0.3769     10720\n",
      "          20     0.0000    0.0000    0.0000      3980\n",
      "          21     0.0000    0.0000    0.0000       122\n",
      "          22     0.2953    0.0445    0.0773      1687\n",
      "          23     0.2609    0.0028    0.0055      2159\n",
      "          24     0.2570    0.2526    0.2548      3809\n",
      "          25     0.0000    0.0000    0.0000      1634\n",
      "          26     0.0000    0.0000    0.0000        82\n",
      "          27     0.0000    0.0000    0.0000       181\n",
      "          28     0.0000    0.0000    0.0000       311\n",
      "          29     0.3333    0.0019    0.0038       530\n",
      "          30     0.0000    0.0000    0.0000       287\n",
      "\n",
      "   micro avg     0.2981    0.2981    0.2981    161256\n",
      "   macro avg     0.1567    0.1169    0.0893    161256\n",
      "weighted avg     0.2340    0.2981    0.1938    161256\n",
      "\n",
      "Accuracy:  0.29813464305204146\n",
      "Precision:  0.23400073362169196\n",
      "Recall:  0.29813464305204146\n",
      "F1:  0.19375465136298967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royce\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\royce\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\royce\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\royce\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "l2_logistic = LogisticRegression(penalty='l2', solver='sag', multi_class='ovr')\n",
    "cv_parameters = {'C':[0.1,1,10]}\n",
    "\n",
    "l2_logistic = fit_classification(l2_logistic,data_dict,cv_parameters=cv_parameters,model_name='L2 Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-12T06:45:25.150Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\royce\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "X_train = data_dict['X_train']\n",
    "y_train = data_dict['y_train']\n",
    "\n",
    "X_test = data_dict['X_test']\n",
    "y_test = data_dict['y_test']\n",
    "\n",
    "model = svm.SVC(probability=True, verbose=10)\n",
    "model.fit(X_train, y_train)\n",
    "results = model.predict_proba(X_test)[0]\n",
    "\n",
    "# gets a dictionary of {'class_name': probability}\n",
    "prob_per_class_dictionary = dict(zip(model.classes_, results))\n",
    "\n",
    "# gets a list of ['most_probable_class', 'second_most_probable_class', ..., 'least_class']\n",
    "results_ordered_by_probability = map(lambda x: x[0], sorted(zip(model.classes_, results), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "prob_per_class_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-12T14:41:27.986Z"
    }
   },
   "outputs": [],
   "source": [
    "prob_per_class_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
